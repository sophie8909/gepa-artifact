uv run python -m scripts.run_experiments --bm_idx 0 --benchmark_name "hoverBench" --num_threads 32 --program_idx 0 --prog_name "HoverMultiHop" --opt_idx 0 --optim_name "Baseline" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0
uv run python -m scripts.run_experiments --bm_idx 0 --benchmark_name "hoverBench" --num_threads 32 --program_idx 0 --prog_name "HoverMultiHop" --opt_idx 1 --optim_name "MIPROv2-Heavy" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt Baseline
uv run python -m scripts.run_experiments --bm_idx 0 --benchmark_name "hoverBench" --num_threads 32 --program_idx 0 --prog_name "HoverMultiHop" --opt_idx 2 --optim_name "GEPA-MERGE" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 0 --benchmark_name "hoverBench" --num_threads 32 --program_idx 0 --prog_name "HoverMultiHop" --opt_idx 3 --optim_name "GEPA" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 0 --benchmark_name "hoverBench" --num_threads 32 --program_idx 0 --prog_name "HoverMultiHop" --opt_idx 4 --optim_name "Abl-SelectBestCandidate" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 0 --benchmark_name "hoverBench" --num_threads 32 --program_idx 0 --prog_name "HoverMultiHop" --opt_idx 5 --optim_name "GRPO" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0
uv run python -m scripts.run_experiments --bm_idx 1 --benchmark_name "HotpotQABench" --num_threads 32 --program_idx 0 --prog_name "HotpotMultiHop" --opt_idx 0 --optim_name "Baseline" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0
uv run python -m scripts.run_experiments --bm_idx 1 --benchmark_name "HotpotQABench" --num_threads 32 --program_idx 0 --prog_name "HotpotMultiHop" --opt_idx 1 --optim_name "MIPROv2-Heavy" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt Baseline
uv run python -m scripts.run_experiments --bm_idx 1 --benchmark_name "HotpotQABench" --num_threads 32 --program_idx 0 --prog_name "HotpotMultiHop" --opt_idx 2 --optim_name "GEPA-MERGE" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 1 --benchmark_name "HotpotQABench" --num_threads 32 --program_idx 0 --prog_name "HotpotMultiHop" --opt_idx 3 --optim_name "GEPA" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 1 --benchmark_name "HotpotQABench" --num_threads 32 --program_idx 0 --prog_name "HotpotMultiHop" --opt_idx 4 --optim_name "Abl-SelectBestCandidate" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 1 --benchmark_name "HotpotQABench" --num_threads 32 --program_idx 0 --prog_name "HotpotMultiHop" --opt_idx 5 --optim_name "GRPO" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0
uv run python -m scripts.run_experiments --bm_idx 2 --benchmark_name "Papillon" --num_threads 32 --program_idx 0 --prog_name "PAPILLON" --opt_idx 0 --optim_name "Baseline" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0
uv run python -m scripts.run_experiments --bm_idx 2 --benchmark_name "Papillon" --num_threads 32 --program_idx 0 --prog_name "PAPILLON" --opt_idx 1 --optim_name "MIPROv2-Heavy" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt Baseline
uv run python -m scripts.run_experiments --bm_idx 2 --benchmark_name "Papillon" --num_threads 32 --program_idx 0 --prog_name "PAPILLON" --opt_idx 2 --optim_name "GEPA-MERGE" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 2 --benchmark_name "Papillon" --num_threads 32 --program_idx 0 --prog_name "PAPILLON" --opt_idx 3 --optim_name "GEPA" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 2 --benchmark_name "Papillon" --num_threads 32 --program_idx 0 --prog_name "PAPILLON" --opt_idx 4 --optim_name "Abl-SelectBestCandidate" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 2 --benchmark_name "Papillon" --num_threads 32 --program_idx 0 --prog_name "PAPILLON" --opt_idx 5 --optim_name "GRPO" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0
uv run python -m scripts.run_experiments --bm_idx 3 --benchmark_name "IFBench" --num_threads 32 --program_idx 0 --prog_name "IFBenchCoT2StageProgram" --opt_idx 0 --optim_name "Baseline" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0
uv run python -m scripts.run_experiments --bm_idx 3 --benchmark_name "IFBench" --num_threads 32 --program_idx 0 --prog_name "IFBenchCoT2StageProgram" --opt_idx 1 --optim_name "MIPROv2-Heavy" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt Baseline
uv run python -m scripts.run_experiments --bm_idx 3 --benchmark_name "IFBench" --num_threads 32 --program_idx 0 --prog_name "IFBenchCoT2StageProgram" --opt_idx 2 --optim_name "GEPA-MERGE" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 3 --benchmark_name "IFBench" --num_threads 32 --program_idx 0 --prog_name "IFBenchCoT2StageProgram" --opt_idx 3 --optim_name "GEPA" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 3 --benchmark_name "IFBench" --num_threads 32 --program_idx 0 --prog_name "IFBenchCoT2StageProgram" --opt_idx 4 --optim_name "Abl-SelectBestCandidate" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 3 --benchmark_name "IFBench" --num_threads 32 --program_idx 0 --prog_name "IFBenchCoT2StageProgram" --opt_idx 5 --optim_name "GRPO" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0
uv run python -m scripts.run_experiments --bm_idx 4 --benchmark_name "LiveBenchMathBench" --num_threads 32 --program_idx 0 --prog_name "CoT" --opt_idx 0 --optim_name "Baseline" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0
uv run python -m scripts.run_experiments --bm_idx 4 --benchmark_name "LiveBenchMathBench" --num_threads 32 --program_idx 0 --prog_name "CoT" --opt_idx 1 --optim_name "MIPROv2-Heavy" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt Baseline
uv run python -m scripts.run_experiments --bm_idx 4 --benchmark_name "LiveBenchMathBench" --num_threads 32 --program_idx 0 --prog_name "CoT" --opt_idx 2 --optim_name "GEPA-MERGE" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 4 --benchmark_name "LiveBenchMathBench" --num_threads 32 --program_idx 0 --prog_name "CoT" --opt_idx 3 --optim_name "GEPA" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 4 --benchmark_name "LiveBenchMathBench" --num_threads 32 --program_idx 0 --prog_name "CoT" --opt_idx 4 --optim_name "Abl-SelectBestCandidate" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 4 --benchmark_name "LiveBenchMathBench" --num_threads 32 --program_idx 0 --prog_name "CoT" --opt_idx 5 --optim_name "GRPO" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0
uv run python -m scripts.run_experiments --bm_idx 5 --benchmark_name "AIMEBench" --num_threads 32 --program_idx 0 --prog_name "CoT" --opt_idx 0 --optim_name "Baseline" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0
uv run python -m scripts.run_experiments --bm_idx 5 --benchmark_name "AIMEBench" --num_threads 32 --program_idx 0 --prog_name "CoT" --opt_idx 1 --optim_name "MIPROv2-Heavy" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt Baseline
uv run python -m scripts.run_experiments --bm_idx 5 --benchmark_name "AIMEBench" --num_threads 32 --program_idx 0 --prog_name "CoT" --opt_idx 2 --optim_name "GEPA-MERGE" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 5 --benchmark_name "AIMEBench" --num_threads 32 --program_idx 0 --prog_name "CoT" --opt_idx 3 --optim_name "GEPA" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 5 --benchmark_name "AIMEBench" --num_threads 32 --program_idx 0 --prog_name "CoT" --opt_idx 4 --optim_name "Abl-SelectBestCandidate" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0 --use_cache_from_opt MIPROv2-Heavy
uv run python -m scripts.run_experiments --bm_idx 5 --benchmark_name "AIMEBench" --num_threads 32 --program_idx 0 --prog_name "CoT" --opt_idx 5 --optim_name "GRPO" --lm_config '{"name": "ollama-llama3.1-8b", "model": "llama3.1:8b", "api_key": "ollama", "api_base": "http://localhost:11434/v1", "temperature": 0.7}' --seed 0
